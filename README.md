## Methods for Machine Comprehension

This project explores the methodology for machine comprehension using a subset of the Stanford Question Answering data set (https://rajpurkar.github.io/SQuAD-explorer/).

The pretrained vector space model is provided by GLOVE. https://nlp.stanford.edu/projects/glove/

The project seeks to recreate the BiDAF architecture "BI-DIRECTIONAL ATTENTION FLOW FOR MACHINE COMPREHENSION" and is based on this project here: https://github.com/allenai/bi-att-flow

The paper can be found on arxiv: https://dblp.uni-trier.de/rec/bibtex/journals/corr/SeoKFH16 

Note also for exploring Glove in R see also: https://rpubs.com/ww44ss/glove300d
Additional examples of loading word vectors into a keras layer is shown in:
https://github.com/rstudio/keras/blob/master/vignettes/examples/pretrained_word_embeddings.R

A good discussion on Attention networks in Keras is here:

https://github.com/keras-team/keras/issues/4962

A good discussion on implementation of attention mechanism in R is here: https://blogs.rstudio.com/tensorflow/posts/2018-07-30-attention-layer/

